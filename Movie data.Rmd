---
title: "Final Takehome Movie Data"
author: "Xinwei Huang Lianna Novitz"
date: "2018 0501"
output: html_document
---

---
title: "Midterm"
author: "Xinwei Huang  Lianna Novitz"
output:
  html_document:
    df_print: paged
---

```{r,echo = FALSE,message=FALSE}
library(ggplot2,warn.conflicts = FALSE)
library(dplyr,warn.conflicts = FALSE)
library(tidyr,warn.conflicts = FALSE)
library(readr,warn.conflicts = FALSE)
library(gridExtra,warn.conflicts = FALSE)
library(GGally,warn.conflicts = FALSE) 
library(leaps,warn.conflicts = FALSE) 
library(glmnet,warn.conflicts = FALSE)
library(purrr,warn.conflicts = FALSE)
library(jsonlite,warn.conflicts = FALSE)
library(curl,warn.conflicts = FALSE)
```

### Part I: Introduction

This dataset includes around 5000 movies and their relative variables. Our group analyzes the variables in it and build up two models to explain what factors would influence the revenue of a movie using forward selection and LASSO methods. 

```{r,echo = FALSE,message=FALSE}
tmdb <- read_csv("https://www.dropbox.com/s/sesaejgna9fkg1q/tmdb_5000.csv?dl=1")
```

```{r,echo = FALSE,message=FALSE}
#Returns the first two characters listed in the credits in their own columns. 
#There is a unique row for each movie ID with at least one character.

chars <-
  tmdb %>% 
  select(id, cast) %>% 
  filter(nchar(cast)>2) %>% 
  mutate(js=map(cast,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(char1 = first(character),
            char2 = nth(character, n=2))

#Returns the first two genres reported in their own columns. 
#There is a unique row for each movie ID with at least one genre.

genres <-
  tmdb %>% 
  select(id, genres) %>% 
  filter(nchar(genres)>2) %>% 
  mutate(js = map(genres,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(genre1 = first(name),
            genre2 = nth(name, n=2))

#Returns the first two key words reported in their own columns. 
#There is a unique row for each movie ID with at least one keyword.

keywords <-
  tmdb %>% 
  select(id, keywords) %>% 
  filter(nchar(keywords)>2) %>% 
  mutate(js = map(keywords,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(keyword1 = first(name),
            keyword2 = nth(name, n=2))


#Returns the first production company. 
#There is a unique row for each movie ID with at least one production company

production_company <-
  tmdb %>% 
  select(id, production_companies) %>% 
  filter(nchar(production_companies)>2) %>% 
  mutate(js = map(production_companies,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(prod_comp_main = first(name))

#Returns the first production country. 
#There is a unique row for each movie ID with at least one production country

production_country <-
  tmdb %>% 
  select(id, production_countries) %>% 
  filter(nchar(production_countries)>2) %>% 
  mutate(js = map(production_countries,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(country_main = first(iso_3166_1))

#Combine the tables created above with the original data and drops some of the columns.

tmdb_enhanced <-
  tmdb %>% 
  select(-genres, -keywords, -production_companies, -production_countries,
         -spoken_languages, -cast, -crew) %>% 
  left_join(chars, 
            by = "id") %>% 
  left_join(genres, 
            by = "id") %>% 
  left_join(keywords, 
            by = "id") %>% 
  left_join(production_country,
            by = "id") %>% 
  left_join(production_company, 
            by = "id")

```



### Part II: Exploring Data

```{r}
summary(tmdb_enhanced)
```

First, we summarize the data and look for the question to answer. The whole dataset has 6 quantitative variables and 17 categorical variables, and among them, revenue is a good dependent variable because it is a good measure of a successful movie. So, we want to build the best model to predict the revenue of a movie, based on the data we have. And then, we want to find one most important explanatory variable which can best explain the revenue of a movie. 

In order to find some good categorical variables to use, we made tables for each of reasonable categorical variables. As the result, some of them are not suitable to be included in the model. For example, the keyword variable has too many categories and each category has few observations. Because the table is too long, we don't show it below. For the similar reason, we decide not to use the characters variable and production company variable. For the genres variable, there are two genres variables, which are shown below. We can see that genre1 variable is good to use because its observations are separated into each category. However, genre2 variable has 928 NAs in it, which means it is not a good option for the independent variable. The last categorical variable we explored is the country variable. As shown in Table 3, most of the movies are actually made in the U.S., and many other countries only have 1 movie in its category, so, we decide to not use it in our model. Other categorical variables like website, title, overview etc. are not actually influencing the revenue made, so we just ignore them. 

```{r,echo = FALSE}
library(knitr)
kable(
  tmdb_enhanced %>% 
    group_by(genre1) %>% 
    count(),
  align = c("l", "c"),
  caption = "Table 1: Distribution of genre1"
)
```

```{r,echo = FALSE}
library(knitr)
kable(
  tmdb_enhanced %>% 
    group_by(genre2) %>% 
    count(),
  align = c("l", "c"),
  caption = "Table 2: Distribution of genre2"
)
```

```{r,echo = FALSE}
library(knitr)
kable(
  tmdb_enhanced %>% 
    group_by(country_main) %>% 
    count(),
  align = c("l", "c"),
  caption = "Table 3: Distribution of countries of production"
)
```

Because we exclude all other categorical variables except the genre1, we made a new dataset that with no N/A in it.  And we observed that there are many 0s in the revenue and budget variable, which is not realistic. So, we remove all observations that have 0 revenue or budget. 

```{r,echo = FALSE}
tmdb_mod <-
  tmdb_enhanced %>%
  select(revenue, budget, popularity, runtime, vote_average, vote_count, genre1,genre2,country_main) %>%
  drop_na()

tmdb_mod1 <-
  tmdb_mod %>% filter(budget!=0, revenue!=0)

```

Next, we analyze the relationship between quantitative variables and our dependent variable revenue. By reasoning, we can see that all 5 quantitative variables other than revenue tend to influence the revenue of a movie. A higher popularity and vote count mean there are more people have seen this movie, which creates more revenue. A higher vote score means the movie is better so that more people are going to watch the movie and thus increases the revenue. A higher budget tends to make better special effects in the movie and thus make it more attractive. And longer runtime means the movie has the longer time to tell the whole story, which may make it more attractive for the audience. So, all 5 quantitative variables are good to be used as independent variables. We plot the relationship between each of those 5 and the revenue variable by establishing simple linear regressions. 

```{r,message=FALSE,echo = FALSE}
budgetmod <- lm(tmdb_mod1$revenue ~ tmdb_mod1$budget)
budgetr <- tmdb_mod %>% 
  ggplot(aes(x=budget, y=revenue)) +
  geom_point(color="red") +
  geom_abline(intercept =  -8.045e+05, slope = 3.015e+00, size = 1)



popularitymod <- lm(tmdb_mod1$revenue ~ tmdb_mod1$popularity)
popularityr <- tmdb_mod %>% 
  ggplot(aes(x=popularity, y=revenue)) +
  geom_point(color="red") +
  geom_abline(intercept = 37116443, slope = 3087125, size = 1)



votecountmod <- lm(tmdb_mod1$revenue ~ tmdb_mod1$vote_count)
votecountr <- tmdb_mod %>% 
  ggplot(aes(x=vote_count, y=revenue)) +
  geom_point(color="red") +
  geom_abline(intercept = 25183820, slope = 100742, size = 1)


voteaveragemod <- lm(tmdb_mod1$revenue ~ tmdb_mod1$vote_average)
voteaverager <- tmdb_mod %>% 
  ggplot(aes(x=vote_average, y=revenue)) +
  geom_point(color="red") +
  geom_abline(intercept = -159639659, slope = 46095474, size = 1)


runtimemod <- lm(tmdb_mod1$revenue ~ tmdb_mod1$runtime)
runtimer <- tmdb_mod %>% 
  ggplot(aes(x=runtime, y=revenue)) +
  geom_point(color="red") +
  geom_abline(intercept =  -117198218, slope = 2241274, size = 1)


grid.arrange(budgetr,popularityr,runtimer,voteaverager,votecountr, ncol=3)
```

We can see from those plots that budget variable and vote_count variable have a good linear relationship with revenue. The rest three variables don't have an obvious linear relationship with revenue, but the simple model regressions show that they are statistically significant in interpreting the revenue. So, we are going to use all of those 5 variables as independent variables. 

### Part III: Checking Model Assumptions
After exploring the data, we want to build up a model including all variables we found suitable to predict revenue and check model assumptions to decide if we want to transform the data. 

```{r,echo = FALSE}
basicmod <- lm(revenue ~ budget + popularity + runtime + vote_average + vote_count + genre1,data = tmdb_mod1)
summary(basicmod)
```
From the model, we see that the p-value of budget, popularity, runtime, and vote_count are all significant, but vote_average is not significant. And for the categorical variable, some of them are significant while others are not. So, we decide to exclude vote_average. And then, we plot the residual vs. fitted value, histogram and qq plots to check the model assumptions. 

```{r,echo = FALSE}
tmdb_mod1 <-
  tmdb_mod1 %>%
  select(revenue, budget, popularity, runtime, vote_count, genre1) 
```

```{r,echo = FALSE}
basicmod1 <- lm(revenue ~ budget + popularity + runtime + vote_count + genre1,data = tmdb_mod1)

rvf <-
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod1$fitted.values, 
         resids = basicmod1$residuals) %>% 
  ggplot(aes(x=fitted.vals, y=resids)) +
  geom_jitter(width = 5) +
  geom_hline(yintercept = 0, color="gray") +
  geom_smooth(se = FALSE)


hist <- 
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod1$fitted.values, 
         resids = basicmod1$residuals) %>% 
  ggplot(aes(x=resids)) +
  geom_histogram()


qq <-
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod1$fitted.values, 
         resids = basicmod1$residuals) %>% 
  ggplot(aes(sample=resids)) +
  geom_qq() 

grid.arrange(rvf,hist,qq, ncol=2)
```

We see that the residuals are clustered at left, and the mean error is increasing as fitted values increases. The histogram of the residuals shows a roughly normal distribution but the qq plot shows a departure of 45 degrees line. So, we try to use the log value of revenue. Afterward, we rebuild the model and check the model assumption again. 

```{r,echo = FALSE}
logrevenue <- log(tmdb_mod1$revenue)
tmdb_mod1$logrevenue <- logrevenue
```


```{r,echo = FALSE}
basicmod2 <- lm(logrevenue~budget + popularity + runtime + vote_count + genre1,data = tmdb_mod1)

rvf1<-
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod2$fitted.values, 
         resids = basicmod2$residuals) %>% 
  ggplot(aes(x=fitted.vals, y=resids)) +
  geom_jitter(width = 5) +
  geom_hline(yintercept = 0, color="gray") +
  geom_smooth(se = FALSE)


hist1<- 
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod2$fitted.values, 
         resids = basicmod2$residuals) %>% 
  ggplot(aes(x=resids)) +
  geom_histogram()


qq1<- 
  tmdb_mod1 %>% 
  mutate(fitted.vals = basicmod2$fitted.values, 
         resids = basicmod2$residuals) %>% 
  ggplot(aes(sample=resids)) +
  geom_qq() 

grid.arrange(rvf1,hist1,qq1, ncol=2)
```

We see that after taking the log revenue, the constant variance and mean error is departing from 0, and the histogram shows that the residual skews to left. The qq plot even departs more from the 45-degree line than non-logged revenue model. So, we decide to use the original revenue as the dependent variable. 



### Part IV: Choose the best model using forward selection. 

In order to get the best model that interpret the revenue, we use the forward selection of the variables. 

```{r, echo = FALSE}
set.seed(10)


tmdb.tr.test <- 
  tmdb_mod1 %>% 
  mutate(grp = sample(c("tr", "test"), size=n(), replace = TRUE, prob = c(.8,.2)))  
  
  
tmdb.train <- tmdb.tr.test %>% 
  filter(grp == "tr") %>% 
  select(-grp)

tmdb.test <- tmdb.tr.test %>% 
  filter(grp == "test") %>% 
  select(-grp)
```

```{r,echo = FALSE}
bestmodels <- regsubsets(x = revenue ~ ., 
                   data = tmdb.train,
                   nvmax = 22,         
                   method = "forward")

summary(bestmodels)
```

Next, we calculate the cv errors of different models in order to find the best model. We are limiting the most number of variables to 10 because more than 10 variables make the model too complicated. 

```{r,echo = FALSE}
predict.regsubsets <- function(object, newdata, id, ...){
  form <- as.formula(object$call[[2]])
  coefi <- coef(object, id=id)
  model.matrix(form, data=newdata)[,names(coefi)] %*% coefi
}
```

```{r,echo = FALSE}
MSPEs = list()
for (i in 1:10){
  prei <- predict.regsubsets(object = bestmodels, 
                   newdata = tmdb.test,
                   id = i)
  MSPEs[i] <- mean((tmdb.test$revenue - prei)^2)
}
MSPEs
```

As the result, 10 variables model has the lowest cv error. So, our model to predict the movie revenue is 
$$
Revenue = B_0+B_1*budget+B_2*popularity+B_3*runtime+B_4*votecount+B_5*genre1Advaenture+B_6*genre1Animation+B_7*genre1Comedy+B_8*genre1Family+B_9*genre1Horror + B_10*genre1Romance
$$

And the coefficients are

```{r}
coef(bestmodels, id=10)
```


Through this model, we can conclude that an increase in budget, popularity, runtime, and vote_count will increase the predicted revenue of a movie. And if the category of the movie is Animation or Family, it tends to increases the revenue of the movie dramatically, while the Adventure, Comedy, Horror and Romance categories also increase the predicted revenue of a movie. 

### Part V: Choose three best explainatory varibles. 

In this section, we want to find out three variables with the largest interpretability. We want to see which variables decide the predicted revenue of a movie most. 
We use LASSO method to decreases the number of variables until three left to find this variable. 

```{r, echo = FALSE}
tmdb.train2 <- tmdb.train %>% 
  drop_na()

tmdb.test2 <- tmdb.test %>%
  drop_na()

x <- model.matrix(revenue ~., data=tmdb.train2)[,-1]
y <- tmdb.train2$revenue
```

```{r, echo = FALSE}
set.seed(10)
cv.tmdb.mod <- cv.glmnet(x = x, y = y, alpha = 1)
```

```{r,echo = FALSE}
lasso.stats <- tibble(lambda = cv.tmdb.mod$lambda,
                      cverror = cv.tmdb.mod$cvm,
                      upper = cv.tmdb.mod$cvup,
                      lower = cv.tmdb.mod$cvlo) 

lasso.stats %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_point(color="red") +
  geom_errorbar(aes(ymin=lower, ymax=upper))

bestlam.cvup <- cv.tmdb.mod$cvup[cv.tmdb.mod$lambda==cv.tmdb.mod$lambda.min]

lasso.stats %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_vline(xintercept = cv.tmdb.mod$lambda.min, color="blue", alpha=.5) +
  geom_hline(yintercept = bestlam.cvup, color="blue", alpha=.5) +
  geom_vline(xintercept = cv.tmdb.mod$lambda.1se, color="orange", alpha=.5) +
  geom_errorbar(aes(ymin=lower, ymax=upper),color="darkgray") +
  geom_point(color="red") +
  scale_x_log10() +
  theme_minimal()
```

The graph above shows that the vcerror increases dramatically after lambda is larger than $1*se$ from the min. So, we begin with the lambda value that 1 se away from the min. 

```{r}
predict(cv.tmdb.mod, 
        type="coefficients", 
        s = c(cv.tmdb.mod$lambda.min,1*10^7,(1.95)*10^7, cv.tmdb.mod$lambda.1se))

```

We tried 4 different lambda values, which are the lambda that minimizes the cv error, $1*10^7$,$(1.95)*10^7$, and the lambda that 1 standard error from the min lambda. As the result, when lambda = $(1.95)*10^7$, we have three variables left. The left variables are budget, popularity, and vote_count. This means that the genre of a movie and other variables do not influence the predicted revenue of a movie as much as its budget, popularity, and number of votes. Therefore, a movie with a high budget tends to have high revenue. And the movie with high popularity and thus more votes in websites tend to have higher revenue. The final model we got is:

$$
Revenue = B_0+B_1*budget+B_2*popularity+B_3*vote_count
$$

### Part VI: Conclusion

In conclusion, using the forward selection, our group find that the best model is $ Revenue = B_0+B_1*budget+B_2*popularity+B_3*runtime+B_4*votecount+B_5*genre1Advaenture+B_6*genre1Animation+B_7*genre1Comedy+B_8*genre1Family+B_9*genre1Horror + B_10*genre1Romance$. The adding of each of those variables will decrease the error of the prediction. Afterward, we use LASSO method to find 3 variables with the largest interpretability for the revenue. As the result, the model we got is $Revenue = B_0+B_1*budget+B_2*popularity+B_3*vote_count$. It turns out that the budget, the popularity and how many people vote for the movie online mostly influence the predicted revenue of a movie. 

### Part VII: Appendix

```{r,eval=FALSE}
#Returns the first two characters listed in the credits in their own columns. 
#There is a unique row for each movie ID with at least one character.

chars <-
  tmdb %>% 
  select(id, cast) %>% 
  filter(nchar(cast)>2) %>% 
  mutate(js=map(cast,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(char1 = first(character),
            char2 = nth(character, n=2))

#Returns the first two genres reported in their own columns. 
#There is a unique row for each movie ID with at least one genre.

genres <-
  tmdb %>% 
  select(id, genres) %>% 
  filter(nchar(genres)>2) %>% 
  mutate(js = map(genres,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(genre1 = first(name),
            genre2 = nth(name, n=2))

#Returns the first two key words reported in their own columns. 
#There is a unique row for each movie ID with at least one keyword.

keywords <-
  tmdb %>% 
  select(id, keywords) %>% 
  filter(nchar(keywords)>2) %>% 
  mutate(js = map(keywords,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(keyword1 = first(name),
            keyword2 = nth(name, n=2))


#Returns the first production company. 
#There is a unique row for each movie ID with at least one production company

production_company <-
  tmdb %>% 
  select(id, production_companies) %>% 
  filter(nchar(production_companies)>2) %>% 
  mutate(js = map(production_companies,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(prod_comp_main = first(name))

#Returns the first production country. 
#There is a unique row for each movie ID with at least one production country

production_country <-
  tmdb %>% 
  select(id, production_countries) %>% 
  filter(nchar(production_countries)>2) %>% 
  mutate(js = map(production_countries,fromJSON)) %>% 
  unnest(js, .drop = FALSE) %>% 
  group_by(id) %>% 
  summarize(country_main = first(iso_3166_1))

#Combine the tables created above with the original data and drops some of the columns.

tmdb_enhanced <-
  tmdb %>% 
  select(-genres, -keywords, -production_companies, -production_countries,
         -spoken_languages, -cast, -crew) %>% 
  left_join(chars, 
            by = "id") %>% 
  left_join(genres, 
            by = "id") %>% 
  left_join(keywords, 
            by = "id") %>% 
  left_join(production_country,
            by = "id") %>% 
  left_join(production_company, 
            by = "id")

```

```{r,eval = FALSE}
# make a new dataset that only contains variables we want
tmdb_mod <-
  tmdb_enhanced %>%
  select(revenue, budget, popularity, runtime, vote_average, vote_count, genre1,genre2,country_main) %>%
  drop_na()

tmdb_mod1 <-
  tmdb_mod %>% filter(budget!=0, revenue!=0)

```

```{r,eval = FALSE}
# delete the variables we found that are not suitable. 
tmdb_mod1 <-
  tmdb_mod1 %>%
  select(revenue, budget, popularity, runtime, vote_count, genre1) 
```
