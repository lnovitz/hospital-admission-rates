---
title: "Hospital-Readmission-Model"
author: "Lianna Novitz"
date: "5/1/2018"
output: html_document
---

```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(readr)
library(gridExtra)
library(GGally) 
library(leaps) 
library(glmnet)
library(faraway)
library(forcats) #to collapse categorical levels
library(ISLR)
library(rpart)
library(rpart.plot)
library(randomForest)
library(knitr)
```

```{r}
diabetes <- read_csv("https://www.dropbox.com/s/odtsp7foaugu694/diabetes_data_clean.csv?dl=1")
```

###Introduction
According to the authors, “The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.

1. It is an inpatient encounter (a hospital admission).
2. It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.
3. The length of stay was at least 1 day and at most 14 days.
4. Laboratory tests were performed during the encounter.
5. Medications were administered during the encounter."

Citation: Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014

###Research Question
It's a problem for hospitals if a patient is readmitted before 30 days, so my question is, what characteristics make a patient more likely to be readmitted before 30 days? How can hospital staff reduce this rate?

First of all, let's see what the rate of readmission before 30 days is.

```{r}
kable(
  diabetes %>% 
    group_by(readmitted) %>% 
    count(),
  align = c("l", "c"),
  caption = "Table 1: Readmission Categories"
)
```
```{r, echo=FALSE}
11357/(11357 + 35545 + 54864)
35545/(11357 + 35545 + 54864)
54864/(11357 + 35545 + 54864)
```
The rate of readmission before 30 days is about 11%. The rate of readmission after 30 days is about 35%. The rate of no readmission is about 54%.

So our job is to find the features which make a hospital patient more likely to be readmitted before 30 days. 

###Exploring Relationships


```{r, warning=FALSE, message=FALSE}
summary(diabetes)
```


```{r, echo=FALSE}
diabetes %>% 
    group_by(race) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(gender) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(age) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(time_in_hospital) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(num_lab_procedures) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(num_procedures) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(num_medications) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(number_outpatient) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(number_emergency) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(number_inpatient) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(number_diagnoses) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(max_glu_serum) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(A1Cresult) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(metformin) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(glimepiride) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(glipizide) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(glyburide) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(pioglitazone) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(rosiglitazone) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(insulin) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(change) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(diabetesMed) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(readmitted) %>% 
    count()
```
```{r}
11357 + 35545
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(admission_source) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(admission_type) %>% 
    count()
```

```{r, echo=FALSE}
diabetes %>% 
    group_by(discharge_disposition) %>% 
    count()
```
I want to find out characteristics about patients who were readmitted before 30 days was up. 

The density plot below may hint that patients who were sent home have slightly higher rates of readmittance before 30 days. 
```{r}
diabetes %>% 
  ggplot(aes(x=discharge_disposition, fill=factor(readmitted))) +
  geom_density(alpha=.5)
```

The boxplot below shows, perhaps, a slightly higher rate of readmission before 30 days is correlated with a higher number of inpatient visits in the year preceding the specific hospital this specific encounter. This intuitively makes sense.

```{r}
diabetes %>% 
  ggplot(aes(x=factor(readmitted), y=number_inpatient)) +
  geom_boxplot()
```
The boxplot below does seem to show a difference between the amount of time spent in the hospital for those readmitted after the encounter and those not readmitted.
```{r}
diabetes %>% 
  ggplot(aes(x=factor(readmitted), y=time_in_hospital)) +
  geom_boxplot()
```

### Decision Tree Model
```{r}
earlyadmit_tree <- rpart(readmitted ~ .,
                 data=diabetes)
```

```{r}
rpart.plot(earlyadmit_tree, under=FALSE, varlen = 0, yesno = 2, ycompress = TRUE)
```

Another tree to see if I can get better detail in the visuals
```{r}
rpart.plot(earlyadmit_tree, # middle graph
type=4,
extra=101, 
box.palette="GnBu",
branch.lty=3, 
shadow.col="gray", 
nn=TRUE
)
```

```{r}
earlyadmit2_tree <- rpart(readmitted ~ discharge_disposition,
                 data=diabetes)
```

```{r}
rpart.plot(earlyadmit2_tree)
```

### Logistic Model

Using this logistic model, we are confined to a binary response variable, so we have to combine levels within readmitted to build a proper model. 

We transformed the readmitted variable so it only has two levels. 

Before the transformation, the readmitted variable contained 3 levels, revealing whether a patient was readmitted before 30 days, after 30 days, or not at all after the recorded encounter.

```{r}
diabetes %>% 
    group_by(readmitted) %>% 
    count()
```

After the transformation, the readmitted variable contains only 2 levels, revealing whether a patient was readmitted at all or not at all after the recorded encounter.
```{r, echo=FALSE}
diabetes2 <- diabetes %>% 
  mutate(readmitted = readmitted %>% fct_collapse(YES = c("<30",">30")))
```

```{r}
diabetes2 %>% 
    group_by(readmitted) %>% 
  count()
```

We also decided to transform the readmitted variable in a different way that contains only 2 levels. Instead of collapsing readmissions into one level, I will treat readmissions after thirty days and no readmissions as one level, and readmissions before thirty days as the second level.
```{r, echo=FALSE}
diabetes3 <- diabetes %>% 
  mutate(readmitted = readmitted %>% fct_collapse(NO = c("NO",">30")))
```

```{r}
diabetes3 %>% 
    group_by(readmitted) %>% 
    count()
```

Now to build our logistic model, we will use the lasso method to control for how many variables we include in the model.
```{r}
log.admit <- glm(readmitted ~ .,
               data=diabetes2, family = binomial(link = "logit"))
```

First we divide the data into a training and validation set.
```{r}
diabetes.trval2 <- diabetes2 %>% 
  mutate(grp = sample(c("train", "validation"), 
                      size=n(), 
                      prob = c(.6,.4),
                      replace=TRUE))
train2 <- diabetes.trval2 %>% filter(grp=="train")
validation2 <- diabetes.trval2 %>% filter(grp=="validation")

diabetes.trval3 <- diabetes3 %>% 
  mutate(grp = sample(c("train", "validation"), 
                      size=n(), 
                      prob = c(.6,.4),
                      replace=TRUE))
train3 <- diabetes.trval3 %>% filter(grp=="train")
validation3 <- diabetes.trval3 %>% filter(grp=="validation")
```

Then we use the lasso method to build our model.
```{r}
x2 <- model.matrix(readmitted ~., data=train2 %>% select(-grp))[,-1]
y2 <- train2$readmitted

x3 <- model.matrix(readmitted ~., data=train3 %>% select(-grp))[,-1]
y3 <- train3$readmitted

#training2$race <- factor(training2$race, levels = c("apple", "orange", "banana"))
#indVar = c(var1, var2, var3)   
#fit =  glmnet(x=data.matrix(train2[,indVar]) , y = train2[,depVar], and other parameters)
#predictions = predict(fit, newx = data.matrix(test[,indVar]))

set.seed(1)
cv.lasso.mod <- cv.glmnet(x = x2, y = y2, alpha = 1, family="binomial")
cv.lasso.mod2 <- cv.glmnet(x = x3, y = y3, alpha = 1, family="binomial")

plot(cv.lasso.mod)
plot(cv.lasso.mod2)
```

```{r}
names(cv.lasso.mod)
cv.lasso.mod$lambda
cv.lasso.mod$cvm
cv.lasso.mod$lambda.min #lambda with the smallest cv error
cv.lasso.mod$lambda.1se #largest lambda such that the cv error is within 1 se
                        # of the smallest cv error
```

There is a plotting function that looks at log($\lambda$) on the x-axis and CV MSE on the y-axis. Because I love ggplot graphics so much, I changed this to a ggplot below.

```{r}
plot(cv.lasso.mod)
plot(cv.lasso.mod2)
```

I put all these values into a dataset to create a "prettier" graph. 
First, make the dataset:
```{r}
lasso.stats <- tibble(lambda = cv.lasso.mod$lambda,
                      cverror = cv.lasso.mod$cvm,
                      upper = cv.lasso.mod$cvup,
                      lower = cv.lasso.mod$cvlo) 

lasso.stats2 <- tibble(lambda = cv.lasso.mod2$lambda,
                      cverror = cv.lasso.mod2$cvm,
                      upper = cv.lasso.mod2$cvup,
                      lower = cv.lasso.mod2$cvlo) 
```


First attempt:
```{r}
lasso.stats %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_point(color="red") +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  xlim(0, 0.002) 

lasso.stats2 %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_point(color="blue") +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  xlim(0, 0.002) 
```

Hmmm, I think I also like lambda on the log scale:

```{r}
bestlam.cvup <- cv.lasso.mod$cvup[cv.lasso.mod$lambda==cv.lasso.mod$lambda.min]
bestlam.cvup2 <- cv.lasso.mod2$cvup[cv.lasso.mod2$lambda==cv.lasso.mod2$lambda.min]


lasso.stats %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_vline(xintercept = cv.lasso.mod$lambda.min, color="blue", alpha=.5) +
  geom_hline(yintercept = bestlam.cvup, color="blue", alpha=.5) +
  geom_vline(xintercept = cv.lasso.mod$lambda.1se, color="orange", alpha=.5) +
  geom_errorbar(aes(ymin=lower, ymax=upper),color="darkgray") +
  geom_point(color="red") +
  scale_x_log10() +
  theme_minimal() +
  xlim(0, 0.002) 
```

```{r}
lasso.stats2 %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_vline(xintercept = cv.lasso.mod2$lambda.min, color="blue", alpha=.5) +
  geom_hline(yintercept = bestlam.cvup2, color="blue", alpha=.5) +
  geom_vline(xintercept = cv.lasso.mod2$lambda.1se, color="orange", alpha=.5) +
  geom_errorbar(aes(ymin=lower, ymax=upper),color="darkgray") +
  geom_point(color="red") +
  scale_x_log10() +
  theme_minimal() +
  xlim(0, 0.05) 
```

THIS GRAPH WILL HELP YOU SEE MORE CLEARLY THE VALUES OF LAMBDA. I have rounded the values.

```{r}
lasso.stats %>% 
  ggplot(aes(x=lambda, y=cverror)) +
  geom_vline(xintercept = cv.lasso.mod$lambda.min, color="blue", alpha=.5) +
  geom_hline(yintercept = bestlam.cvup, color="blue", alpha=.5) +
  geom_vline(xintercept = cv.lasso.mod$lambda.1se, color="orange", alpha=.5) +
  geom_errorbar(aes(ymin=lower, ymax=upper),color="darkgray") +
  geom_point(color="red") +
  geom_text(aes(label = round(lambda,0)), size=3, nudge_y = 5000, angle=45) +
  scale_x_log10() +
  theme_minimal()
```

How do I see the models that were fit? We can use the *predict* function and tell it we want the coefficients as output and give it new values of *lambda*. Below, we look at the models for the value of $\lambda$ with the smallest cv error and the largest value of $\lambda$ with cv error within one se of the smallest cv error, and $\lambda= 25$, which is between the two. NOTE: I HAD A MISTAKE IN THIS PIECE OF CODE!!! I originally had *lasso.mod.hitters* and it should be *cv.lasso.mod*.

```{r}
predict(cv.lasso.mod, 
        type="coefficients", 
        s = c(cv.lasso.mod$lambda.min, cv.lasso.mod$lambda.1se, 0.001))
```

```{r}
predict(cv.lasso.mod2, 
        type="coefficients", 
        s = c(cv.lasso.mod2$lambda.min, cv.lasso.mod2$lambda.1se, 0.006))
```
1 standard deviation away from the mean test error, the lasso method gives us a model with only 4 variables. This model is for Version 2 of the readmitted variable, which treats patients readmitted before 30 days as its own level, and all other patients (readmitted after 30 days or not readmitted at all) as a separate level. 


**QUESTIONS**

* How would you go about using this method to build a model?
* What if you want to compare this method with another method, like forward selection?

```{r}
predict(cv.lasso.mod, type="coefficients", 
        s=c(cv.lasso.mod$lambda.1se))
```
```{r}
predict(cv.lasso.mod2, type="coefficients", 
        s=c(cv.lasso.mod2$lambda.1se))
```

```{r, eval=FALSE}
predict(cv.lasso.mod,
        newx = model.matrix(readmitted ~., data=validation2 %>% select(-grp))[,-1],
        type="response", 
        s=c(cv.lasso.mod$lambda.1se))
```
